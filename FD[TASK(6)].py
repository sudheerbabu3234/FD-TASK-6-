# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m0E-OdzKX5eie0GV0CsdypTAG5I_kHEP
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

df = pd.read_csv("creditcard.csv")
print(df.head())
print(df['Class'].value_counts())

from sklearn.preprocessing import StandardScaler
import pandas as pd

# Load the dataset again to ensure fresh columns
df = pd.read_csv("creditcard.csv")

# Create a safe copy
df_copy = df.copy()

# Only scale if columns exist
if 'Amount' in df_copy.columns and 'Time' in df_copy.columns:
    scaler = StandardScaler()
    df_copy['scaled_amount'] = scaler.fit_transform(df_copy[['Amount']])
    df_copy['scaled_time'] = scaler.fit_transform(df_copy[['Time']])

    # Drop originals
    df_copy.drop(['Amount', 'Time'], axis=1, inplace=True)

    # Reorder columns: scaled_time, scaled_amount, all other V columns, Class
    reordered_cols = ['scaled_time', 'scaled_amount'] + \
                     [col for col in df_copy.columns if col not in ['scaled_time', 'scaled_amount', 'Class']] + \
                     ['Class']
    scaled_df = df_copy[reordered_cols]

    print("✅ Scaling successful. New dataframe is ready.")
else:
    print("❌ 'Amount' or 'Time' column not found in the dataset.")

X = scaled_df.drop("Class", axis=1)
y = scaled_df["Class"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

from sklearn.impute import SimpleImputer

# Use mean imputation
imputer = SimpleImputer(strategy='mean')
X_train_imputed = imputer.fit_transform(X_train)
X_test_imputed = imputer.transform(X_test)

# Now train logistic regression
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train_imputed, y_train)
y_pred_lr = lr.predict(X_test_imputed)

print("Missing values in training data:", X_train.isnull().sum().sum())
print("Missing values in test data:", X_test.isnull().sum().sum())

# Remove NaNs from y_test and sync with y_pred_rf
valid_indices_rf = ~pd.isnull(y_test)
clean_y_test_rf = y_test[valid_indices_rf]
clean_y_pred_rf = y_pred_rf[valid_indices_rf]

# Print classification report for Random Forest
print("Random Forest:")
print(classification_report(clean_y_test_rf, clean_y_pred_rf, zero_division=0))
sns.heatmap(confusion_matrix(clean_y_test_rf, clean_y_pred_rf), annot=True, fmt='d')
plt.title("Confusion Matrix - Random Forest")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# Remove NaNs from y_test and sync with y_pred_lr
valid_indices_lr = ~pd.isnull(y_test)
clean_y_test_lr = y_test[valid_indices_lr]
clean_y_pred_lr = y_pred_lr[valid_indices_lr]

# Print classification report for Logistic Regression
print("Logistic Regression:")
print(classification_report(clean_y_test_lr, clean_y_pred_lr, zero_division=0))
sns.heatmap(confusion_matrix(clean_y_test_lr, clean_y_pred_lr), annot=True, fmt='d')
plt.title("Confusion Matrix - Logistic Regression")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()